[2019-05-23 19:16:38,174] Starting training with params:
{'name': 'rn18/0', 'model': 'models.MultiResnet18', 'model_params': {'num_filters': 16, 'pretrained': False, 'num_classes': 2}, 'loss': 'losses.CrossEntropyLoss', 'loss_params': {}, 'metrics': ['losses.CrossEntropyLoss'], 'steps_per_epoch': 2500, 'new_save': True, 'name_save': './tt_1', 'save_dir': PosixPath('trained_models/weights/rn18/0')}


[2019-05-23 19:16:38,298] Starting stage:
{'load_best': False, 'optimizer': 'Adam', 'optimizer_params': {'lr': 0.001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-06}, 'epochs': 300, 'augmentation': 'mix_transform'}

[2019-05-23 19:16:38,298] Epoch 0 | optimizer "Adam" | lr 0.001
[2019-05-23 19:18:02,538] Starting training with params:
{'name': 'rn18/0', 'model': 'models.MultiResnet18', 'model_params': {'num_filters': 16, 'pretrained': False, 'num_classes': 2}, 'loss': 'losses.CrossEntropyLoss', 'loss_params': {}, 'metrics': ['losses.CrossEntropyLoss'], 'steps_per_epoch': 2500, 'new_save': True, 'name_save': './tt_1', 'save_dir': PosixPath('trained_models/weights/rn18/0')}


[2019-05-23 19:18:02,574] Starting stage:
{'load_best': False, 'optimizer': 'Adam', 'optimizer_params': {'lr': 0.001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-06}, 'epochs': 300, 'augmentation': 'mix_transform'}

[2019-05-23 19:18:02,574] Epoch 0 | optimizer "Adam" | lr 0.001
[2019-05-23 19:19:16,693] Starting training with params:
{'name': 'rn18/0', 'model': 'models.MultiResnet18', 'model_params': {'num_filters': 16, 'pretrained': False, 'num_classes': 2}, 'loss': 'losses.CrossEntropyLoss', 'loss_params': {}, 'metrics': ['losses.CrossEntropyLoss'], 'steps_per_epoch': 2500, 'new_save': True, 'name_save': './tt_1', 'save_dir': PosixPath('trained_models/weights/rn18/0')}


[2019-05-23 19:19:16,736] Starting stage:
{'load_best': False, 'optimizer': 'Adam', 'optimizer_params': {'lr': 0.001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-06}, 'epochs': 300, 'augmentation': 'mix_transform'}

[2019-05-23 19:19:16,736] Epoch 0 | optimizer "Adam" | lr 0.001
[2019-05-23 19:22:11,757] Starting training with params:
{'name': 'rn18/0', 'model': 'models.MultiResnet18', 'model_params': {'num_filters': 16, 'pretrained': False, 'num_classes': 2}, 'loss': 'losses.CrossEntropyLoss', 'loss_params': {}, 'metrics': ['losses.CrossEntropyLoss'], 'steps_per_epoch': 2500, 'new_save': True, 'name_save': './tt_1', 'save_dir': PosixPath('trained_models/weights/rn18/0')}


[2019-05-23 19:22:11,798] Starting stage:
{'load_best': False, 'optimizer': 'Adam', 'optimizer_params': {'lr': 0.001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-06}, 'epochs': 300, 'augmentation': 'mix_transform'}

[2019-05-23 19:22:11,798] Epoch 0 | optimizer "Adam" | lr 0.001
[2019-05-23 19:24:33,071] Starting training with params:
{'name': 'rn18/0', 'model': 'models.MultiResnet18', 'model_params': {'num_filters': 16, 'pretrained': False, 'num_classes': 2}, 'loss': 'losses.CrossEntropyLoss', 'loss_params': {}, 'metrics': ['losses.CrossEntropyLoss'], 'steps_per_epoch': 2500, 'new_save': True, 'name_save': './tt_1', 'save_dir': PosixPath('trained_models/weights/rn18/0')}


[2019-05-23 19:24:33,093] Starting stage:
{'load_best': False, 'optimizer': 'Adam', 'optimizer_params': {'lr': 0.001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-06}, 'epochs': 300, 'augmentation': 'mix_transform'}

[2019-05-23 19:24:33,093] Epoch 0 | optimizer "Adam" | lr 0.001
[2019-05-23 19:25:18,601] Starting training with params:
{'name': 'rn18/0', 'model': 'models.MultiResnet18', 'model_params': {'num_filters': 16, 'pretrained': False, 'num_classes': 2}, 'loss': 'losses.CrossEntropyLoss', 'loss_params': {}, 'metrics': ['losses.CrossEntropyLoss'], 'steps_per_epoch': 2500, 'new_save': True, 'name_save': './tt_1', 'save_dir': PosixPath('trained_models/weights/rn18/0')}


[2019-05-23 19:25:18,628] Starting stage:
{'load_best': False, 'optimizer': 'Adam', 'optimizer_params': {'lr': 0.001}, 'scheduler': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-06}, 'epochs': 300, 'augmentation': 'mix_transform'}

[2019-05-23 19:25:18,628] Epoch 0 | optimizer "Adam" | lr 0.001
